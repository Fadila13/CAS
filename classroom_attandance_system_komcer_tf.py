# -*- coding: utf-8 -*-
"""Classroom Attandance System_Komcer TF

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p6Gr48xgzMhsnMKD3-zYzXo-tHm5lTBC

# **Classroom Attandance System**
**By. Teddi dan Fadila**

*Instalasi Library yang Diperlukan*
"""

!pip install mtcnn keras-facenet tensorflow opencv-python-headless scikit-learn matplotlib pandas

"""## **Import Library yang Diperlukan**"""

import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mtcnn import MTCNN
from keras_facenet import FaceNet
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

"""## **Unggah dan Siapkan Dataset Wajah**"""

from google.colab import drive
drive.mount('/content/drive')

data_path = '/content/drive/My Drive/dataset'

import os

# Cek isi folder dataset
print(os.listdir('/content/drive/My Drive/dataset'))

"""## **Model dan Arsitektur**

### **Deteksi Wajah Menggunakan MTCNN**
"""

from mtcnn import MTCNN
import cv2

detector = MTCNN()

def detect_and_crop_faces(image_path):
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    faces = detector.detect_faces(img_rgb)
    face_crops = []
    for face in faces:
        x, y, width, height = face['box']
        face_crop = img_rgb[y:y+height, x:x+width]
        face_crop = cv2.resize(face_crop, (160, 160))
        face_crops.append(face_crop)
    return face_crops

"""### **Ekstraksi Fitur Wajah Menggunakan FaceNet**"""

from keras_facenet import FaceNet

embedder = FaceNet()

def get_face_embeddings(face_crops):
    embeddings = [embedder.embeddings([face])[0] for face in face_crops]
    return embeddings

"""### **Persiapan Data dan Label**"""

import os
from glob import glob
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
import numpy as np

# Path utama dataset
data_path = '/content/drive/My Drive/dataset/'  # Sesuaikan dengan path dataset Anda

# Inisialisasi list untuk embeddings dan nama
names = []
embeddings = []

# Looping melalui folder dataset
for folder in os.listdir(data_path):
    folder_path = os.path.join(data_path, folder)
    if os.path.isdir(folder_path):
        print(f"\nProcessing folder: {folder}")  # Memeriksa nama folder yang sedang diproses

        # Ambil semua gambar di dalam folder ini
        image_paths = glob(os.path.join(folder_path, "*.jpg"))

        # Cek jika folder memiliki gambar
        if not image_paths:
            print(f"No images found in folder: {folder}")
            continue  # Lewatkan folder jika tidak ada gambar

        for img_path in image_paths:
            print(f"Processing image: {img_path}")  # Memeriksa setiap gambar

            # Proses deteksi wajah dan ekstraksi fitur
            faces = detect_and_crop_faces(img_path)  # Pastikan ini mengembalikan list wajah yang terdeteksi
            face_embeddings = get_face_embeddings(faces)  # Pastikan ini mengembalikan list numpy array

            # Tambahkan embedding dan nama siswa ke list
            embeddings.extend(face_embeddings)
            names.extend([folder] * len(face_embeddings))  # Nama otomatis dari folder

print("Folders in dataset:", os.listdir(data_path))  # Tampilkan semua folder

"""### **Split Data untuk Training dan Validation**"""

import os
import cv2
import numpy as np
from keras_facenet import FaceNet
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import pickle

# Inisialisasi FaceNet
embedder = FaceNet()

# Fungsi untuk ekstraksi fitur dari gambar wajah
def extract_face_embedding(img_path):
    img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    face = cv2.resize(img_rgb, (160, 160))  # Sesuaikan ukuran untuk FaceNet
    embedding = embedder.embeddings([face])[0]
    return embedding

# Variabel untuk menyimpan embeddings dan names
embeddings = []
names = []

# Akses setiap folder (nama orang) dalam dataset
dataset_path = '/content/drive/My Drive/dataset/'  # Ganti dengan path ke folder dataset Anda
for person_name in os.listdir(dataset_path):
    person_folder = os.path.join(dataset_path, person_name)

    # Cek apakah path ini adalah folder
    if os.path.isdir(person_folder):
        for image_name in os.listdir(person_folder):
            image_path = os.path.join(person_folder, image_name)
            try:
                # Ekstraksi embedding dari setiap gambar dan tambahkan ke embeddings
                embedding = extract_face_embedding(image_path)
                embeddings.append(embedding)
                names.append(person_name)
            except Exception as e:
                print(f"Error processing {image_path}: {e}")

# Verifikasi panjang embeddings dan names
print("Jumlah embeddings:", len(embeddings))
print("Jumlah names:", len(names))

# Pastikan embeddings dan names tidak kosong dan memiliki panjang yang sama
if len(embeddings) == 0 or len(embeddings) != len(names):
    raise ValueError("Data embeddings atau names kosong atau jumlahnya tidak sesuai.")

# Konversi embeddings ke array numpy
embeddings = np.array(embeddings)

# Encode names menjadi labels numerik
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(names)

# Simpan LabelEncoder untuk digunakan nanti dalam pengenalan
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(label_encoder, f)

# Bagi data menjadi training dan validation
X_train, X_val, y_train, y_val = train_test_split(embeddings, labels, test_size=0.2, random_state=42)

# Cek hasil split
print("Pembagian data selesai:")
print("Jumlah data training:", len(X_train))
print("Jumlah data validation:", len(X_val))

"""### **Membangun Model ANN untuk Klasifikasi**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Fungsi untuk membangun model ANN
def create_ann_model(input_shape, num_classes):
    model = Sequential()
    model.add(Dense(128, input_shape=(input_shape,), activation='relu'))  # Layer input dengan 128 neuron
    model.add(Dense(64, activation='relu'))  # Hidden layer dengan 64 neuron
    model.add(Dense(32, activation='relu'))  # Hidden layer dengan 32 neuron
    model.add(Dense(num_classes, activation='softmax'))  # Output layer dengan jumlah kelas

    # Kompilasi model
    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Asumsi input_shape adalah panjang embeddings dan num_classes adalah jumlah label unik
input_shape = X_train.shape[1]  # Panjang embeddings
num_classes = len(np.unique(y_train))  # Jumlah label unik (misalnya, jumlah siswa)

# Bangun model
model = create_ann_model(input_shape, num_classes)

# Tampilkan ringkasan model
model.summary()

# Latih model ANN
history = model.fit(X_train, y_train, epochs=20, batch_size=8, validation_data=(X_val, y_val))

# Evaluasi model pada data validation
val_loss, val_accuracy = model.evaluate(X_val, y_val)
print(f"Validation Accuracy: {val_accuracy:.2f}")

model.save('face_recognition_model.keras')

"""### **Visualisasi Hasil Pelatihan**"""

import matplotlib.pyplot as plt

# Plot akurasi
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""### **Evaluasi Model**"""

print("X_val shape:", X_val.shape)
print("y_val shape:", y_val.shape)

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(embeddings, labels, test_size=0.2, random_state=42)

print("Jumlah embeddings:", len(embeddings))
print("Jumlah labels:", len(labels))

val_loss, val_accuracy = model.evaluate(X_val, y_val)
print(f"Validation Loss: {val_loss:.2f}")
print(f"Validation Accuracy: {val_accuracy:.2f}")

"""### **Menyimpan Model dan Label Encoder**"""

model.save('face_recognition_model.keras')
import pickle
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(label_encoder, f)

"""## **Pengenalan Wajah dan Pencatatan Kehadiran**

### **Pengenalan dan Pencatatan Kehadiran**
"""

import pandas as pd

def recognize_faces(embeddings):
    predictions = model.predict(embeddings)
    recognized_faces = label_encoder.inverse_transform(np.argmax(predictions, axis=1))
    return recognized_faces

# Mencatat kehadiran
def log_attendance(names):
    df = pd.DataFrame(names, columns=['Name'])
    df['Attendance'] = 'Present'
    df.to_csv('attendance.csv', mode='a', header=False)  # Tersimpan sebagai riwayat kehadiran

"""### **Menjalankan Pengenalan Wajah dalam Satu Frame**"""

from google.colab import files
uploaded = files.upload()
image_path = list(uploaded.keys())[0]  # Mengambil nama file gambar yang diunggah

img = cv2.imread(image_path)
if img is None:
    print("Error: Gambar tidak terbaca. Periksa file path atau coba unggah ulang.")
else:
    print("Gambar berhasil terbaca.")

if img is not None:
    detector = MTCNN()
    faces = detector.detect_faces(img)
    for face in faces:
        x, y, width, height = face['box']
        cv2.rectangle(img, (x, y), (x + width, y + height), (255, 0, 0), 2)

    # Tampilkan gambar hasil deteksi
    import matplotlib.pyplot as plt
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

from tensorflow.keras.models import load_model
import pickle

# Muat model yang telah dilatih
model = load_model('face_recognition_model.keras')

# Muat label encoder untuk konversi label numerik menjadi nama
with open('label_encoder.pkl', 'rb') as f:
    label_encoder = pickle.load(f)

# Fungsi untuk ekstraksi embedding wajah dan pengenalan nama
embedder = FaceNet()

def get_face_embeddings(face_crop):
    return embedder.embeddings([face_crop])[0]

def recognize_face(face_crop):
    embedding = get_face_embeddings(face_crop)
    embedding = embedding.reshape(1, -1)  # Sesuaikan bentuk untuk input ke model
    prediction = model.predict(embedding)
    name = label_encoder.inverse_transform([np.argmax(prediction)])[0]
    return name

if img is not None:
    detector = MTCNN()
    faces = detector.detect_faces(img)

    for face in faces:
        x, y, width, height = face['box']
        face_crop = img[y:y+height, x:x+width]
        face_crop = cv2.resize(face_crop, (160, 160))  # Resize ke ukuran yang sesuai untuk FaceNet

        # Kenali wajah menggunakan fungsi recognize_face
        name = recognize_face(face_crop)

        # Gambar kotak deteksi dan nama pada gambar
        cv2.rectangle(img, (x, y), (x + width, y + height), (255, 0, 0), 2)
        cv2.putText(img, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    # Tampilkan gambar hasil deteksi dan pengenalan nama
    import matplotlib.pyplot as plt
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

# Fungsi untuk mengenali wajah dan memastikan prediksi model
def recognize_face(face_crop):
    embedding = get_face_embeddings(face_crop)
    embedding = embedding.reshape(1, -1)  # Bentuk sesuai input model
    prediction = model.predict(embedding)

    print("Prediksi model (probabilitas):", prediction)  # Cek hasil prediksi

    name = label_encoder.inverse_transform([np.argmax(prediction)])[0]
    return name

def recognize_face(face_crop):
    embedding = get_face_embeddings(face_crop)
    embedding = embedding.reshape(1, -1)
    prediction = model.predict(embedding)

    max_prob = np.max(prediction)  # Probabilitas tertinggi
    if max_prob < 0.5:  # Threshold
        name = "Unknown"
    else:
        name = label_encoder.inverse_transform([np.argmax(prediction)])[0]

    print("Nama terdeteksi:", name, "| Probabilitas:", max_prob)
    return name

if img is not None:
    detector = MTCNN()
    faces = detector.detect_faces(img)

    for face in faces:
        x, y, width, height = face['box']
        face_crop = img[y:y+height, x:x+width]
        face_crop = cv2.resize(face_crop, (160, 160))  # Resize ke ukuran yang sesuai untuk FaceNet

        # Kenali wajah menggunakan fungsi recognize_face
        name = recognize_face(face_crop)

        # Gambar kotak deteksi dan nama pada gambar
        cv2.rectangle(img, (x, y), (x + width, y + height), (255, 0, 0), 2)
        cv2.putText(img, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    # Tampilkan gambar hasil deteksi dan pengenalan nama
    import matplotlib.pyplot as plt
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

if img is not None:
    detector = MTCNN()
    faces = detector.detect_faces(img)

    for face in faces:
        x, y, width, height = face['box']
        face_crop = img[y:y+height, x:x+width]
        face_crop = cv2.resize(face_crop, (160, 160))  # Resize ke ukuran yang sesuai untuk FaceNet

        # Kenali wajah menggunakan fungsi recognize_face
        name = recognize_face(face_crop)

        # Gambar kotak deteksi dan nama pada gambar
        cv2.rectangle(img, (x, y), (x + width, y + height), (255, 0, 0), 2)
        cv2.putText(img, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    # Tampilkan gambar hasil deteksi dan pengenalan nama
    import matplotlib.pyplot as plt
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

if img is not None:
    detector = MTCNN()
    faces = detector.detect_faces(img)

    for face in faces:
        x, y, width, height = face['box']
        face_crop = img[y:y+height, x:x+width]
        face_crop = cv2.resize(face_crop, (160, 160))  # Resize ke ukuran yang sesuai untuk FaceNet

        # Kenali wajah menggunakan fungsi recognize_face
        name = recognize_face(face_crop)

        # Gambar kotak deteksi wajah pada gambar
        cv2.rectangle(img, (x, y), (x + width, y + height), (0, 255, 0), 3)  # Kotak hijau lebih tebal

        # Tentukan posisi teks nama agar berada sedikit di atas kotak deteksi
        text_y = y - 20 if y - 20 > 20 else y + 20  # Menambah jarak lebih jauh di atas kotak

        # Menambah ketebalan outline dengan menggambar beberapa lapis teks hitam
        for i in range(8, 0, -2):
            cv2.putText(img, name, (x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), i)  # Outline hitam bertingkat

        # Teks putih di atas outline
        cv2.putText(img, name, (x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4)  # Teks putih lebih tebal

    # Tampilkan gambar hasil deteksi dan pengenalan nama
    import matplotlib.pyplot as plt
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()